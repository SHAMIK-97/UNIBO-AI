{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using several classifiers and tuning parameters - Parameters grid\n",
    "[From official `scikit-learn` documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html)\n",
    "\n",
    "Adapted by Claudio Sartori\n",
    "\n",
    "Example of usage of the ***model selection*** features of `scikit-learn` and comparison of several classification methods.\n",
    "1. import a sample dataset \n",
    "1. split the dataset into two parts: train and test\n",
    "    - the *train* part will be used for training and validation (i.e. for *development*)\n",
    "    - the *test* part will be used for test (i.e. for *evaluation*)\n",
    "    - the fraction of test data will be _ts_ (a value of your choice between 0.2 and 0.5)\n",
    "1. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) performs multiple cross-validation experiments to train and test a model with different combinations of parameter values\n",
    "    - for each parameter we set a list of values to test, the `fit` method will generate every possible combination, fit a model with it and evaluate its performance\n",
    "    - we choose a *score function* which will be used for the optimization\n",
    "        - e.g. `accuracy_score`, `precision_score`, `cohen_kappa_score`, `f1_score`, see [this](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) and [this](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for reference\n",
    "    - the output is a dictionary that contains \n",
    "        - the set of parameters which maximize the score \n",
    "        - the test scores\n",
    "1. prepare the parameters for the grid\n",
    "    - it is a list of dictionaries\n",
    "1. set the parameters by cross validation and the *score functions* to choose from\n",
    "1. Loop on scores and, for each score, loop on the model labels (see details below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prepare the environment\n",
    "The `dataset` module contains, among others, a few sample datasets.\n",
    "\n",
    "See this [page](http://scikit-learn.org/stable/datasets/index.html) for reference\n",
    "\n",
    "In the following:\n",
    "- Load a dataset using the `dataset` module  (output refers to the wine dataset)\n",
    "- Prepare the data and the target in X and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    150 examples -- 4 features -- 3 classes\n"
     ]
    }
   ],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "print(\"{:7} examples -- {} features -- {} classes\"\\\n",
    "      .format(X.shape[0],X.shape[1], np.unique(y).shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)  \n",
       "count        150.000000  \n",
       "mean           1.199333  \n",
       "std            0.762238  \n",
       "min            0.100000  \n",
       "25%            0.300000  \n",
       "50%            1.300000  \n",
       "75%            1.800000  \n",
       "max            2.500000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset.data)\n",
    "df.columns = dataset.feature_names\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split:\n",
    "- Set the test set size `ts`. \n",
    "- Set the random state to 44.\n",
    "- Split the dataset into the train and test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 105 examples\n"
     ]
    }
   ],
   "source": [
    "ts = 0.3\n",
    "random_state = 44\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=ts, random_state=random_state)\n",
    "print(\"Training on %d examples\" % len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try GridSearchCV with a DecisionTreeClassifier\n",
    "Use `GridSearchCV` to get the best `max_depth` value for a `DecisionTreeClassifier` evaluating accuracy:\n",
    "- Define the parameters to be tested and the range of values for each one\n",
    "- Get a `GridSearchCV` instance for a `DecisionTreeClassifier`\n",
    "- Fit the instance to the training data\n",
    "\n",
    "**It's ok to get results that are different than the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "dt_params = [{'max_depth': range(1, 20)}]\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), \n",
    "                   param_grid=dt_params, \n",
    "                   scoring='accuracy', cv=5,\n",
    "                   return_train_score = False,\n",
    "                   n_jobs = 2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
      "@author: scikit-learn.org and Claudio Sartori\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "@author: scikit-learn.org and Claudio Sartori\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # uncomment this line to suppress warnings\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "print(__doc__) # print information included in the triple quotes at the beginning\n",
    "\n",
    "# Loading a standard dataset\n",
    "#dataset = datasets.load_digits()\n",
    "# dataset = datasets.fetch_olivetti_faces() # 40 classes!\n",
    "# dataset = datasets.fetch_covtype()        # 581012 examples\t 54 features \n",
    "dataset = datasets.load_iris()    # 150 examples -- 4 features -- 3 classes\n",
    "# dataset = datasets.load_wine()      # 178 examples -- 13 features -- 3 classes\n",
    "# dataset = datasets.load_breast_cancer() # binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The function below groups all the outputs\n",
    "Write a `print_results` function that takes a fitted model and uses its attributes to inspect the results of the search with the parameter grid.\n",
    "\n",
    "The attributes are:<br>\n",
    "`model.best_params_`<br>\n",
    "`model.cv_results_['mean_test_score']`<br>`\n",
    "model.cv_results_['std_test_score']`<br>\n",
    "`model.cv_results_['params']`\n",
    "\n",
    "The report is generated by the `classification_report` function imported from `sklearn.metrics`, which takes as argument the true test labels and the predicted test labels.\n",
    "\n",
    "The +/- in the results is obtained doubling the `std_test_score`. Mean and standard test scores are computed considering the various results on the cross-validation chunks.\n",
    "\n",
    "The function will be used to print the results for each set of parameters in the last part of the exercise.\n",
    "\n",
    "Use `print_results` to show the result of the tuning above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on train set:\n",
      "\n",
      "{'max_depth': 6}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.667 (+/-0.000) for {'max_depth': 1}\n",
      "0.924 (+/-0.076) for {'max_depth': 2}\n",
      "0.905 (+/-0.085) for {'max_depth': 3}\n",
      "0.924 (+/-0.047) for {'max_depth': 4}\n",
      "0.924 (+/-0.047) for {'max_depth': 5}\n",
      "0.952 (+/-0.060) for {'max_depth': 6}\n",
      "0.943 (+/-0.071) for {'max_depth': 7}\n",
      "0.952 (+/-0.060) for {'max_depth': 8}\n",
      "0.914 (+/-0.038) for {'max_depth': 9}\n",
      "0.933 (+/-0.047) for {'max_depth': 10}\n",
      "0.933 (+/-0.047) for {'max_depth': 11}\n",
      "0.933 (+/-0.047) for {'max_depth': 12}\n",
      "0.933 (+/-0.047) for {'max_depth': 13}\n",
      "0.952 (+/-0.060) for {'max_depth': 14}\n",
      "0.924 (+/-0.047) for {'max_depth': 15}\n",
      "0.933 (+/-0.047) for {'max_depth': 16}\n",
      "0.943 (+/-0.071) for {'max_depth': 17}\n",
      "0.952 (+/-0.060) for {'max_depth': 18}\n",
      "0.952 (+/-0.060) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "print_results(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loop on scores and, for each score, loop on the model labels\n",
    "- iterate varying the score function\n",
    "    1. iterate varying the classification model among Decision Tree, Naive Bayes, Linear Perceptron, Support Vector\n",
    "        - activate the *grid search*\n",
    "            1. the resulting model will be the best one according to the current score function\n",
    "        - print the best parameter set and the results for each set of parameters using the above defined function\n",
    "        - print the classification report\n",
    "        - store the `.best score_` in a dictionary for a final report\n",
    "    1. print the final report for the current *score funtion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is intended to ease the remainder of the exercise\n",
    "\n",
    "model_lbls = [\n",
    "             # 'dt', \n",
    "             # 'nb', \n",
    "#              'lp', \n",
    "             'svc', \n",
    "             # 'knn',\n",
    "            ]\n",
    "\n",
    "# Set the parameters to be explored by the grid for each classifier\n",
    "tuned_param_dt = [{'max_depth': list(range(1,20))}]\n",
    "tuned_param_nb = [{'var_smoothing': [10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-07, 1e-8, 1e-9, 1e-10]}]\n",
    "tuned_param_lp = [{'early_stopping': [True]}]\n",
    "tuned_param_svc = [{'kernel': ['rbf'], \n",
    "                    'gamma': [1e-3, 1e-4],\n",
    "                    'C': [1, 10, 100, 1000],\n",
    "                    },\n",
    "                    {'kernel': ['linear'],\n",
    "                     'C': [1, 10, 100, 1000],                     \n",
    "                    },\n",
    "                   ]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(), \n",
    "           'param': tuned_param_dt,\n",
    "          },\n",
    "    'nb': {'name': 'Gaussian Naive Bayes',\n",
    "           'estimator': GaussianNB(),\n",
    "           'param': tuned_param_nb\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(),\n",
    "           'param': tuned_param_lp,\n",
    "          },\n",
    "    'svc':{'name': 'Support Vector      ',\n",
    "           'estimator': SVC(), \n",
    "           'param': tuned_param_svc\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': tuned_param_knn\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "# scores to be explored\n",
    "scores = [\n",
    "          'precision', \n",
    "#           'recall',\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Support Vector      \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on train set:\n",
      "\n",
      "0.117 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.117 (+/-0.016) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.933 (+/-0.072) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.117 (+/-0.016) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.955 (+/-0.055) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.933 (+/-0.072) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.950 (+/-0.065) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.955 (+/-0.055) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.950 (+/-0.065) for {'C': 1, 'kernel': 'linear'}\n",
      "0.942 (+/-0.046) for {'C': 10, 'kernel': 'linear'}\n",
      "0.942 (+/-0.046) for {'C': 100, 'kernel': 'linear'}\n",
      "0.948 (+/-0.092) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "Summary of results for precision\n",
      "Estimator\n",
      "Support Vector      \t - score: 95.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/csartori/opt/anaconda3/envs/sklearn1.0/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results_short = {}\n",
    "\n",
    "for score in scores:\n",
    "    print('='*40)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    #'%s_macro' % score ## is a string formatting expression\n",
    "    # the parameter after % is substituted in the string placeholder %s\n",
    "    for m in model_lbls:\n",
    "        print('-'*40)\n",
    "        print(\"Trying model {}\".format(models[m]['name']))\n",
    "        clf = GridSearchCV(models[m]['estimator'], models[m]['param'], cv=5,\n",
    "                           scoring='%s_macro' % score, \n",
    "#                            iid = False, \n",
    "                           return_train_score = False,\n",
    "                           n_jobs = 2, # this allows using multi-cores\n",
    "                           )\n",
    "        clf.fit(X_train, y_train)\n",
    "        print_results(clf)\n",
    "        results_short[m] = clf.best_score_\n",
    "    print(\"Summary of results for {}\".format(score))\n",
    "    print(\"Estimator\")\n",
    "    for m in results_short.keys():\n",
    "        print(\"{}\\t - score: {:5.2f}%\".format(models[m]['name'], results_short[m]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc': 0.9546296296296296}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='2', ylabel='3'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data = clf.best_estimator_.support_vectors_, x = 2, y = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
